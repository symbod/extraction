---
title: "Method Comparison"
author: "Vivien Wiltzsch & Klaudia Adamowicz"
date: "2024-06-11"
output: 
  html_document:
    toc : true
    toc_depth: 2
    number_sections: true
---

## Setup 

This section loads the necessary libraries for the analysis and sets some initial parameters such as color mapping and random seed for reproducibility.

```{r setup, include=FALSE}
library_names <- c("readr", "ggplot2", "dplyr", "tidyr", "stringr", "data.table",
                   "purrr", "forcats", "patchwork", "matrixStats", "gridExtra", "ComplexUpset")

for (lib in library_names) {
  library(lib, character.only = TRUE)
}

# set random number seed
seed = 27
set.seed(seed)


# Define color mapping for Fractions
fraction_colors <- c("AI" = "royalblue", "AS" = "palegreen3", "single" = "coral", "Summary" = "tan")

```

## Data Loading

Here, the raw data files are loaded into R. This includes the main dataset and the metadata file, which will be used for subsequent analysis steps.

```{r load_data}
# Adjust path as necessary for your file locations
dataset_unsorted <- fread("data/report.pg_matrix.tsv")[, ID := .I]
meta_data <- fread("data/meta_data.csv")

# Define the final output directory or set NULL if results should note be saved
final_out_dir <- "results"
# Creates the folder if it doesn't exist
if(!is.null(final_out_dir)){dir.create(final_out_dir, recursive = TRUE, showWarnings = FALSE)}
```

## Data Preperation

```{r}
sub_dir <- paste0(file.path(final_out_dir,"overview"))
dir.create(sub_dir, recursive = TRUE, showWarnings = FALSE)
```


### Data Trimming

The column names of the loaded dataset are cleaned up in this step. This involves removing specific prefixes and suffixes to standardize the column names, making them easier to work with.

```{r prepare_data}
# Clean up column names in dataset
# Remove specific prefix and suffix from column names
prefix <- "/mnt/ag_proteomik/shared_worktmp/20240126_CaGe_Knochenextraktion ohne Label_Thess/Knochenextrakte_"
suffix <- "_Slot.*"

names(dataset_unsorted) <- sub(suffix, "", sub(prefix, "", names(dataset_unsorted)))
```

### Data Sorting

In this section, the metadata is prepared for sorting, and the main dataset's columns are reordered based on this sorted metadata. This ensures that the dataset columns follow a meaningful order, aligning with the metadata.

```{r sort_data}
# Prepare meta_data for sorting
# Extract numerical part from 'Column' for sorting purposes
meta_data[, M_value := as.numeric(sub("M", "", sub("-.*", "", Column)))]

# Define custom order for Buffer_type and apply it
buffer_order <- c("AS", "AI", "AS1", "AI1", "AI2", "AS2", "single")
meta_data[, Buffer_name := factor(Buffer_name, levels = buffer_order)]

# Sort meta_data based on multiple criteria
ordered_meta_data <- meta_data[order(M_value, Repl_Techn, Repl_Biol, Buffer_name)]

# Sort column names in dataset_unsorted
descr_columns <- names(dataset_unsorted)[!names(dataset_unsorted) %in% ordered_meta_data$Column]
new_order <- c(descr_columns, ordered_meta_data$Column)
dataset_sorted <- dataset_unsorted[, ..new_order]
```

### Data Transformation and Merging

The sorted dataset is transformed into a long format, which is more suitable for certain types of analysis. Following this, the dataset is merged with the metadata, enriching it with additional information necessary for analysis.

```{r}
# Melt dataset_sorted into a long format
dataset_long <- melt(dataset_sorted, 
                     id.vars = descr_columns, 
                     variable.name = "Sample.ID", 
                     value.name = "maxLfQ_intensities")

# Merge dataset_long with meta_data
dataset_merged <- merge(dataset_long, meta_data, by.x = "Sample.ID", by.y = "Column", all.x = TRUE)

write_tsv(dataset_merged, file.path(sub_dir, "report.pg_matrix_long.tsv"))
```

## Number of Quantified Proteins

### Per Sample

This plot shows the number of quantified proteins for each sample, grouped by method and colored by buffer type.

```{r}
# Count the number of non-NA maxLfQ_intensities for each Sample.ID within each Method
dataset_count <- dataset_merged[!is.na(maxLfQ_intensities), .(Protein_Count = .N), by = .(Method, Sample.ID, Buffer_type)]

# Set the order of Sample.ID in dataset_count to match the order in ordered_meta_data$Column
dataset_count$Sample.ID <- factor(dataset_count$Sample.ID, levels = ordered_meta_data$Column)

# Create the barplot
p1 <- ggplot(dataset_count, aes(x = Sample.ID, y = Protein_Count, fill = Buffer_type)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  facet_wrap(~ Method, scales = "free_x", ncol = 2) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Number of Quantified Proteins per Sample, by Method",
       y = "Number of Quantified Proteins", x = "Sample ID", fill = "Buffer Type") +
  scale_fill_manual(values = fraction_colors)

# Save the plot
ggsave(file.path(sub_dir, "Proteins_per_Sample_by_Method.png"), plot = p1)
```

### Per Buffer_name

This plot illustrates the number of quantified proteins for each buffer name, grouped by method and colored by buffer type.

```{r}
dataset_filtered <- dataset_merged[Repl_Techn == 1 & !is.na(maxLfQ_intensities)]
dataset_filtered_repl <- dataset_filtered[, .(Unique_Repl_Biol_Count = uniqueN(Repl_Biol)), by = .(Method, Buffer_name, Buffer_type, ID)]

dataset_count <- dataset_filtered_repl[, .(Protein_Count = .N), by = .(Method, Buffer_name, Buffer_type)]

# Create the barplot
p2 <- ggplot(dataset_count, aes(x = Buffer_name, y = Protein_Count, fill = Buffer_type)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  geom_text(aes(label = Protein_Count), vjust = -0.3, position = position_dodge(width = 0.9), size = 3) +
  facet_wrap(~ Method, scales = "free_x", ncol = 2) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Number of Quantified Proteins per Buffer, by Method",
       y = "Number of Quantified Proteins", x = "Buffer Name", fill = "Buffer Type") +
  scale_fill_manual(values = fraction_colors)

# Save the plot
ggsave(file.path(sub_dir, "Proteins_per_Buffer_by_Method.png"), plot = p2)
```

### In 3 of 4 Biological Replicates in Buffer

This plot shows the number of quantified proteins per buffer for each method, highlighting proteins present in at least 3 of 4 biological replicates.

```{r}
dataset_filtered_in_3_of_4_repl <- dataset_filtered_repl[Unique_Repl_Biol_Count >= 3]

combined_dataset_count <- rbind(
  dataset_count[, Source := "Total"],
  dataset_filtered_in_3_of_4_repl[, .(Protein_Count = .N, Source = "3 of 4 biol. Replicates"), by = .(Method, Buffer_name, Buffer_type)]
)

# Create the barplot
p3 <- ggplot(combined_dataset_count, aes(x = Buffer_name, y = Protein_Count, fill = Buffer_type, alpha = Source)) +
  geom_bar(aes(group = Source), stat = "identity", position = position_dodge(width = 0.8)) +
  geom_text(aes(label = Protein_Count, group = Source), 
            position = position_dodge(width = 0.8), vjust = -0.3, size = 3) + 
  facet_wrap(~ Method, scales = "free_x", ncol = 2) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Number of Quantified Proteins per Buffer, by Method",
       y = "Number of Quantified Proteins", x = "Buffer Name", fill = "Buffer Type") +
  scale_fill_manual(values = fraction_colors) + 
  scale_alpha_discrete(range = c(0.9, 0.5)) + ylim(0, 6000)

# Save the plot
ggsave(file.path(sub_dir, "Proteins_in_3_of_4_BiolRep_by_Method.png"), plot = p3)
```

```{r}
# Create the barplot with protein count comparison
p4 <- ggplot(combined_dataset_count[combined_dataset_count$Source !="Total"], aes(x = Method, y = Protein_Count, fill = Buffer_type)) +
  geom_bar(aes(group = interaction(Buffer_name, Method)), stat = "identity", width = 0.8, position = position_dodge2(width = 0.9, preserve = "single"), alpha = 0.9) +
  geom_text(aes(label = Protein_Count, group = interaction(Buffer_name, Method)), position = position_dodge2(width = 0.9, preserve = "single"), vjust = -0.5, hjust = 0.5, size = 3) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Number of Quantified Proteins per Buffer, by Method",
       y = "Number of Quantified Proteins", x = "Buffer Name", fill = "Buffer Type") +
  scale_fill_manual(values = fraction_colors) + 
  ylim(0, 6000)

# Save the plot
ggsave(file.path(sub_dir, "Proteins_per_Buffer_by_Method_with_Comparison.png"), plot = p4)

```


### In 3 of 4 Biological Replicates in Buffer with total unique

This plot displays the number of quantified proteins per buffer for each method, including a summary bar for total unique proteins.

```{r}
# Calculate unique proteins for each method
unique_proteins <- dataset_filtered_in_3_of_4_repl[, .(Protein_Count = uniqueN(ID)), by = Method]
unique_proteins[, `:=`(Buffer_name = "All Buffers", Buffer_type = "Summary", Source = "3 of 4 biol. Replicates")]

unique_proteins2 <- dataset_filtered_repl[, .(Protein_Count = uniqueN(ID)), by = Method]
unique_proteins2[, `:=`(Buffer_name = "All Buffers", Buffer_type = "Summary", Source = "Total")]

# Combine data
combined_dataset_count2 <- rbind(combined_dataset_count, unique_proteins, unique_proteins2, fill = TRUE)

# Create and save the barplot
p5 <- ggplot(combined_dataset_count2, aes(x = Buffer_name, y = Protein_Count, fill = Buffer_type, alpha = Source)) +
  geom_bar(aes(group = Source), stat = "identity", position = position_dodge(width = 0.8)) +
  geom_text(aes(label = Protein_Count, group = Source), position = position_dodge(width = 0.8), vjust = -0.3, size = 3) + 
  facet_wrap(~ Method, scales = "free_x", ncol = 2) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Number of Quantified Proteins per Buffer, by Method",
       y = "Number of Quantified Proteins", x = "Buffer Name", fill = "Buffer Type") +
  scale_fill_manual(values = fraction_colors) + 
  scale_alpha_discrete(range = c(0.9, 0.5)) + ylim(0, 6000)

ggsave(file.path(sub_dir, "Proteins_per_Buffer_by_Method_with_Summary.png"), plot = p5)
```

```{r}
# Create the barplot
p6 <- ggplot(combined_dataset_count2[Source != "Total"], aes(x = Method, y = Protein_Count, fill = Buffer_type)) +
  geom_bar(aes(group = interaction(Buffer_name, Method)), stat = "identity", width = 0.8, position = position_dodge2(width = 0.9, preserve = "single"), alpha = 0.9) +
  geom_text(aes(label = Protein_Count, group = interaction(Buffer_name, Method)), position = position_dodge2(width = 0.9, preserve = "single"), vjust = -0.5, hjust = 0.5, size = 3) +
  facet_wrap(~ Source, scales = "free_x") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Number of Quantified Proteins per Buffer, by Method",
       y = "Number of Quantified Proteins", x = "Buffer Name", fill = "Buffer Type") +
  scale_fill_manual(values = fraction_colors) +
  ylim(0, 6000)

# Save the plot
ggsave(file.path(sub_dir, "Proteins_per_Buffer_by_Method_with_Summary.png"), plot = p6)
```


### Per Method 

```{r}
combined_dataset_count2 <- rbind(
  dataset_filtered_repl[, .(Protein_Count = uniqueN(ID), Source = "Total"), by = Method],
  dataset_filtered_in_3_of_4_repl[, .(Protein_Count = uniqueN(ID), Source = "3 of 4 biol. Replicates"), by = Method]
)

p7 <- ggplot(combined_dataset_count2, aes(x = Method, y = Protein_Count, fill = Source)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.9)) +
  geom_text(aes(label = Protein_Count), vjust = -0.3, position = position_dodge(width = 0.9), size = 3) +
  labs(title = "Protein Counts per Method (Technical Replicate 1)", 
       y = "No. of quantified proteins", 
       x = "Method", 
       fill = "Quantified Proteins") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_y_continuous(breaks = seq(0, 6000, by = 1000), limits = c(0, 6000)) +
  scale_fill_manual(values = c("Total" = "#4D8DB4", "3 of 4 biol. Replicates" = "#005B7F"),
                    labels = c("3 of 4 biol. Replicates", "Total"))

# Save the plot
ggsave(file.path(sub_dir, "Protein_Counts_per_Method.png"), plot = p7)

```

## Gained IDs

```{r}
dataset_filtered_in_3_of_4 <- merge(
  dataset_filtered, 
  dataset_filtered_in_3_of_4_repl[, .(Method, Buffer_name, ID)], 
  by = c("Method", "Buffer_name", "ID")
)
```

### Gain per Buffer

```{r}
# Define the order of buffers for each method
buffer_order <- list(
  `4step` = c("AS1", "AI1", "AI2", "AS2"),
  `2step+` = c("AS", "AI"),
  `2step` = c("AS", "AI"),
  `1step+` = c("single"),
  `1step` = c("single")
)

# Step 1: Group by Method and Buffer, count unique IDs
method_buffer_ids <- dataset_filtered_in_3_of_4 %>%
  group_by(Method, Buffer_name) %>%
  summarise(IDs = list(unique(ID)), .groups = 'drop')

# Step 2: Calculate new IDs added for each buffer in order
new_ids_by_method <- lapply(names(buffer_order), function(method) {
  # Subset data for the method
  subset_data <- method_buffer_ids %>%
    filter(Method == method) %>%
    arrange(match(Buffer_name, buffer_order[[method]]))  # Arrange by the specified buffer order

  # Initialize cumulative IDs
  cumulative_ids <- unique(unlist(subset_data$IDs[1]))
  new_ids_count <- c(length(cumulative_ids))
  
  # Compute cumulative and new IDs
  if(nrow(subset_data) > 1){
    for (i in 2:nrow(subset_data)) {
      current_ids <- unique(unlist(subset_data$IDs[i]))
      new_ids <- setdiff(current_ids, cumulative_ids)
      cumulative_ids <- union(cumulative_ids, current_ids)
      new_ids_count <- c(new_ids_count, length(new_ids))
    }
  }
  
  data.frame(
    Buffer_name = subset_data$Buffer_name,
    CumulativeIDCount = cumsum(new_ids_count),
    NewIDsAdded = new_ids_count
  )
})
new_ids_by_method <- setNames(new_ids_by_method, names(buffer_order))
```


## Statistics


```{r}
sub_dir <- paste0(file.path(final_out_dir,"statistics"))
dir.create(sub_dir, recursive = TRUE, showWarnings = FALSE)
```


```{r}
# Calculate the statistics for each sample type
stats_df <- dataset_filtered_in_3_of_4 %>%
  group_by(ID, Protein.Group, Genes, First.Protein.Description, Method, Buffer_name) %>%
  summarize(
    MedianLFQ = median(maxLfQ_intensities, na.rm = TRUE),
    MeanLFQ = mean(maxLfQ_intensities, na.rm = TRUE),
    SDLFQ = sd(maxLfQ_intensities, na.rm = TRUE),
    CVLFQ = (sd(maxLfQ_intensities, na.rm = TRUE) / mean(maxLfQ_intensities, na.rm = TRUE)) * 100,
    .groups = 'drop') 

#combined_df <- stats_df %>% arrange(Protein.Group, Genes, Method, Buffer_name)
```


```{r}
# Prepend "M" to the existing M_value
meta_data <- meta_data %>%
  mutate(M = paste0("M", M_value))
```

```{r}
# Calculate the intensities for each biological replicate
replicate_intensities <- dataset_filtered %>%
  group_by(ID, Protein.Group, Genes, First.Protein.Description, M_value, Buffer_name, Repl_Biol) %>%
  summarize(Intensity = mean(maxLfQ_intensities, na.rm = TRUE), .groups = 'drop') %>%
  mutate(M = paste0("M", M_value))

# Pivot the replicate intensities
replicate_intensities <- replicate_intensities %>%
  mutate(B = paste0("B", Repl_Biol)) %>%
  unite("M_B_Repl", M, Buffer_name, B, sep = "-") %>%
  select(-Repl_Biol, -M_value) %>%
  pivot_wider(names_from = M_B_Repl, values_from = Intensity)
```


```{r}
# Create a mapping for Method to the corresponding M value
method_mapping <- unique(meta_data[, .(Method, M)])

# Add a new column M-B to stats_df using the mapping
stats_df_long <- stats_df %>%
  left_join(method_mapping, by = "Method") %>%
  mutate(M_B = paste0(M, "-", Buffer_name)) %>%
  select(-Method, -Buffer_name)

# Reshape the data to create new columns for each M-B combination
stats_df_long <- stats_df_long %>%
  pivot_longer(cols = c(MedianLFQ, MeanLFQ, SDLFQ, CVLFQ), names_to = "Metric", values_to = "Value") %>%
  unite("M_B_Metric", M_B, Metric, sep = "_") %>%
  select(-M) %>%
  pivot_wider(names_from = M_B_Metric, values_from = Value)


final_df <- stats_df_long %>%
  right_join(replicate_intensities, by = c("ID", "Protein.Group", "Genes", "First.Protein.Description")) %>%
  arrange(ID)

final_df <- final_df %>%
  select(
    ID, Protein.Group, Genes, First.Protein.Description,
    `M3-single-B1`, `M3-single-B2`, `M3-single-B3`, `M3-single-B4`, `M3-single_MedianLFQ`, `M3-single_MeanLFQ`, `M3-single_SDLFQ`, `M3-single_CVLFQ`,
    `M4-single-B1`, `M4-single-B2`, `M4-single-B3`, `M4-single-B4`, `M4-single_MedianLFQ`, `M4-single_MeanLFQ`, `M4-single_SDLFQ`, `M4-single_CVLFQ`,
    `M2-AS-B1`, `M2-AS-B2`, `M2-AS-B3`, `M2-AS-B4`, `M2-AS_MedianLFQ`, `M2-AS_MeanLFQ`, `M2-AS_SDLFQ`, `M2-AS_CVLFQ`,
    `M2-AI-B1`, `M2-AI-B2`, `M2-AI-B3`, `M2-AI-B4`, `M2-AI_MedianLFQ`, `M2-AI_MeanLFQ`, `M2-AI_SDLFQ`, `M2-AI_CVLFQ`,
    `M1-AS-B1`, `M1-AS-B2`, `M1-AS-B3`, `M1-AS-B4`, `M1-AS_MedianLFQ`, `M1-AS_MeanLFQ`, `M1-AS_SDLFQ`, `M1-AS_CVLFQ`,
    `M1-AI-B1`, `M1-AI-B2`, `M1-AI-B3`, `M1-AI-B4`, `M1-AI_MedianLFQ`, `M1-AI_MeanLFQ`, `M1-AI_SDLFQ`, `M1-AI_CVLFQ`,
    `M5-AS1-B1`, `M5-AS1-B2`, `M5-AS1-B3`, `M5-AS1-B4`, `M5-AS1_MedianLFQ`, `M5-AS1_MeanLFQ`, `M5-AS1_SDLFQ`, `M5-AS1_CVLFQ`,
    `M5-AI1-B1`, `M5-AI1-B2`, `M5-AI1-B3`, `M5-AI1-B4`, `M5-AI1_MedianLFQ`, `M5-AI1_MeanLFQ`, `M5-AI1_SDLFQ`, `M5-AI1_CVLFQ`,
    `M5-AI2-B1`, `M5-AI2-B2`, `M5-AI2-B3`, `M5-AI2-B4`, `M5-AI2_MedianLFQ`, `M5-AI2_MeanLFQ`, `M5-AI2_SDLFQ`, `M5-AI2_CVLFQ`,
    `M5-AS2-B1`, `M5-AS2-B2`, `M5-AS2-B3`, `M5-AS2-B4`, `M5-AS2_MedianLFQ`, `M5-AS2_MeanLFQ`, `M5-AS2_SDLFQ`, `M5-AS2_CVLFQ`
  )

write.csv(final_df, file.path(sub_dir, "statistics_df.csv"), row.names = FALSE)
```

#### CV

```{r}
df <- stats_df

# Create BufferType based on Buffer_name
df$BufferType <- ifelse(grepl("AI", df$Buffer_name), "AI",
                        ifelse(grepl("AS", df$Buffer_name), "AS", "single"))

# Create a combined column for Method and Buffer_name to use as x-axis labels
df <- df %>%
  mutate(Method_Buffer = paste(Method, Buffer_name, sep = " - "))

# Define the desired order of levels for Method_Buffer
levels_order <- c("1step - single", "1step+ - single", "2step - AS", "2step - AI", 
                  "2step+ - AS", "2step+ - AI", "4step - AS1", "4step - AI1", 
                  "4step - AI2", "4step - AS2")

# Set the levels of Method_Buffer
df <- df %>%
  mutate(Method_Buffer = factor(Method_Buffer, levels = levels_order))

# Define colors for the general buffer types for the legend
general_colors <- c("AI" = "royalblue", "AS" = "palegreen3", "single" = "coral")

# Determine positions for vertical lines to separate the methods
method_positions <- df %>%
  group_by(Method) %>%
  summarize(position = min(as.numeric(Method_Buffer)) - 0.5) %>%
  filter(position > 0)

# Create the violin plot with overlaid boxplot and vertical lines
ggplot(df, aes(x = Method_Buffer, y = CVLFQ, fill = BufferType)) +
  geom_violin(trim = FALSE) +
  geom_boxplot(width = 0.1, fill = "white", outlier.shape = NA) +  # Add boxplot
  geom_vline(data = method_positions, aes(xintercept = position), linetype = "dotted", color = "black") +
  theme_minimal() +
  labs(title = "Distribution of CVLFQ by Buffer Name and Method",
       x = "Method - Buffer Name",
       y = "CVLFQ") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_fill_manual(values = general_colors)

```

## Attributes

```{r}
library("UniprotR")
#GetProteomeFasta("UP000002494" , directorypath = "data/")
```

```{r}
library(Biostrings)

# Define the path to the FASTA file
fasta_file <- "data/UP000002494.fasta"

# Read the FASTA file
fasta_sequences <- readAAStringSet(fasta_file)

# Extract Protein IDs and sequences
protein_ids <- names(fasta_sequences)
sequences <- as.character(fasta_sequences)

# Create a data frame mapping Protein IDs to sequences
protein_sequence_map <- data.frame(ProteinID = protein_ids, Sequence = sequences, stringsAsFactors = FALSE)

# Split the ProteinID by '|' and extract the second element
protein_sequence_map$ProteinID <- sapply(strsplit(protein_sequence_map$ProteinID, "\\|"), `[`, 2)

```



```{r}
result_df <- final_df[c("ID", "Protein.Group", "Genes", "First.Protein.Description")] %>%
  mutate(Protein.ID = Protein.Group) %>%
  separate_rows(Protein.ID, sep = ";") %>%
  distinct() %>%
  left_join(protein_sequence_map, by = c("Protein.ID" = "ProteinID")) 

```

```{r}
library("Peptides")
# Function to calculate properties for a sequence
calculate_properties <- function(seq) {
  if (is.na(seq)) {
    return(data.frame(pI = NA, mw = NA, gravy = NA))
  }
  pI_value <- pI(seq = seq, pKscale = "Bjellqvist")
  mw_value <- mw(seq = seq, monoisotopic = FALSE)
  gravy_value <- hydrophobicity(seq = seq, scale = "KyteDoolittle")
  return(data.frame(pI = pI_value, mw = mw_value, gravy = gravy_value))
}

# Apply the function to each sequence in the data frame
properties_df <- do.call(rbind, lapply(result_df$Sequence, calculate_properties))

# Combine the properties with the original data frame
result_with_properties_df <- cbind(result_df, properties_df)

```

```{r}
attributes_df <- result_with_properties_df %>%
  group_by(ID, Protein.Group, Genes, First.Protein.Description) %>%
  summarize(
    mean_pI = mean(pI, na.rm = TRUE),
    mean_mw = mean(mw, na.rm = TRUE),
    mean_gravy = mean(gravy, na.rm = TRUE)
  ) %>%
  ungroup()

write.csv(attributes_df, file.path(sub_dir, "attributes_df.csv"), row.names = FALSE)
```

```{r}
final_attributes_df <- attributes_df %>%
  inner_join(final_df, by = c("ID", "Protein.Group", "Genes", "First.Protein.Description"))

write.csv(attributes_df, file.path(sub_dir, "attributes_statistics_df.csv"), row.names = FALSE)
```


## Step 2 vs Step 2+

```{r}
sub_dir <- paste0(file.path(final_out_dir,"2step_vs_2stepplus"))
dir.create(sub_dir, recursive = TRUE, showWarnings = FALSE)
```

```{r}
library(openxlsx)

# Function to extract and save unique and shared IDs for a given method
save_ids_to_excel <- function(method_name, file_name) {
  # Determine unique and shared IDs
  buffer_groups <- dataset_filtered_in_3_of_4[Method == method_name, .N, by = .(ID, Buffer_name)]
  unique_ids <- buffer_groups[, .N, by = ID][N == 1, ID]
  shared_ids <- buffer_groups[, .N, by = ID][N > 1, ID]
  
  # Extract unique IDs per Buffer_name
  unique_as_ids <- buffer_groups[Buffer_name == "AS" & ID %in% unique_ids, ID]
  unique_ai_ids <- buffer_groups[Buffer_name == "AI" & ID %in% unique_ids, ID]
  
  # Define columns to extract
  columns_to_extract <- c("Protein.Group", "Protein.Ids", "Protein.Names", "Genes", "First.Protein.Description", "ID")
  
  # Create data frames for each set of IDs
  unique_as_df <- dataset_sorted[ID %in% unique_as_ids, ..columns_to_extract]
  unique_ai_df <- dataset_sorted[ID %in% unique_ai_ids, ..columns_to_extract]
  shared_df <- dataset_sorted[ID %in% shared_ids, ..columns_to_extract]
  
  # Save the data frames to separate sheets in an Excel file
  write.xlsx(list("Unique_AS" = unique_as_df, "Unique_AI" = unique_ai_df, "Shared" = shared_df), file = file_name)
}

# Apply the function for both methods
save_ids_to_excel("2step", file.path(sub_dir,"2step_IDs.xlsx"))
save_ids_to_excel("2step+", file.path(sub_dir,"2step_plus_IDs.xlsx"))
```


```{r}
# Extract unique IDs for each buffer and method combination
buffer_groups <- dataset_filtered_in_3_of_4_repl[, .N, by = .(ID, Buffer_name, Method)]
sets <- list(
  `2step+ AI` = buffer_groups[Buffer_name == "AI" & Method == "2step+", ID],
  `2step+ AS` = buffer_groups[Buffer_name == "AS" & Method == "2step+", ID],
  `2step AI` = buffer_groups[Buffer_name == "AI" & Method == "2step", ID],
  `2step AS` = buffer_groups[Buffer_name == "AS" & Method == "2step", ID]
)

# Create a data frame to represent the presence/absence of each ID in the sets
all_ids <- unique(unlist(sets))
upset_data <- as.data.frame(sapply(sets, function(x) as.integer(all_ids %in% x)))

# Create the UpSet plot
upset_plot <- UpSetR::upset(
  upset_data,
  sets = names(upset_data),
  keep.order = TRUE,
  order.by = "freq",
  main.bar.color = "black",
  sets.bar.color = c("royalblue", "palegreen3", "royalblue", "palegreen3"),
  text.scale = 1.5,
  mainbar.y.label = "Intersection Size",
  sets.x.label = "Set Size",
  set_size.show = TRUE,
  set_size.scale_max = 6000
)

# Save the plot
png(filename = file.path(sub_dir, "Comparison_of_AS_and_AI_Buffers_Across_2step_and_2step_plus_Methods.png"), width = 1200, height = 800)
print(upset_plot)
#grid.text("Comparison of AS and AI Buffers Across 2step and 2step+ Methods", x = 0.5, y = 0.97, gp = gpar(fontsize #= 14, fontface = "bold"))
dev.off()
```


```{r}
library(VennDiagram)
library(grid)

# Function to create and save Venn diagram
create_and_save_venn <- function(ai_ids, as_ids, method_label, sub_dir, filename) {
  venn.plot <- venn.diagram(
    x = list(
      AI = unique(ai_ids),
      AS = unique(as_ids)
    ),
    category.names = c("AS", "AI"),
    filename = NULL,
    fill = c("palegreen3", "royalblue"),
    alpha = 0.5,
    cex = 2,
    cat.cex = 2,
    cat.pos = c(200, 20),
    cat.dist = 0.05,
    cat.col = c("palegreen3", "royalblue"),
    margin = 0.1
  )

  # Save the Venn diagram
  png(filename = file.path(sub_dir, filename), width = 800, height = 600)
  grid.newpage()
  grid.draw(venn.plot)
  grid.text(paste("Intersection of AS and AI in", method_label, "Method"), x = 0.5, y = 0.95, gp = gpar(fontsize = 16, fontface = "bold"))
  dev.off()
}
```

```{r}
# Create and save Venn diagram for "2step"
create_and_save_venn(unique_ids_2step_ai$ID, unique_ids_2step_as$ID, "2step", sub_dir, "VennDiagram_2step.png")

# Create and save Venn diagram for "2step+"
create_and_save_venn(unique_ids_2step_plus_ai$ID, unique_ids_2step_plus_as$ID, "2step+", sub_dir, "VennDiagram_2step_plus.png")
```

#### Scatter

```{r}
library(viridis)

# Function to calculate density
get_density <- function(x, y, n = 100) {
  dens <- MASS::kde2d(x, y, n = n)
  ix <- findInterval(x, dens$x)
  iy <- findInterval(y, dens$y)
  dens$z[cbind(ix, iy)]
}

# Function to create scatterplot with correlation
create_scatterplot_with_correlation <- function(df, method_label, log_scale = FALSE, sub_dir, filename) {
  # Step 1: Filter the dataset for the specified method
  filtered_df <- df %>%
    filter(Method == method_label)

  # Step 2: Identify shared IDs
  shared_ids <- filtered_df %>%
    group_by(ID) %>%
    filter(n_distinct(Buffer_name) > 1) %>%
    pull(ID) %>%
    unique()

  # Step 3: Subset the data for shared IDs
  shared_data <- filtered_df %>%
    filter(ID %in% shared_ids)

  # Step 4: Reshape the data to have one row per ID with columns for each buffer
  shared_data_wide <- shared_data %>%
    select(-MedianLFQ, -SDLFQ, -CVLFQ) %>%
    pivot_wider(names_from = Buffer_name, values_from = MeanLFQ, names_prefix = "MeanLFQ_")
  
  # Step 5: Apply log scale if flag is set
  if (log_scale) {
    shared_data_wide <- shared_data_wide %>%
      mutate(across(starts_with("MeanLFQ_"), log2))
  }

  # Step 6: Calculate the correlation
  correlation <- cor(shared_data_wide$MeanLFQ_AS, shared_data_wide$MeanLFQ_AI, use = "complete.obs")
  
  # Step 7: Calculate density for coloring
  shared_data_wide$density <- get_density(shared_data_wide$MeanLFQ_AS, shared_data_wide$MeanLFQ_AI, n = 100)

  # Step 8: Create the scatterplot
 p <- ggplot(shared_data_wide, aes(x = MeanLFQ_AS, y = MeanLFQ_AI, color = density)) +
    geom_point() +
    scale_color_viridis() +
    geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "gray") +
    labs(title = paste("Scatterplot of Shared IDs between AS and AI Buffers in", method_label, "Method"),
         x = if (log_scale) "Log2 MeanLFQ Intensity in AS Buffer" else "MeanLFQ Intensity in AS Buffer",
         y = if (log_scale) "Log2 MeanLFQ Intensity in AI Buffer" else "MeanLFQ Intensity in AI Buffer") +
    theme_minimal() +
    coord_equal() +
    annotate("text", x = Inf, y = Inf, label = paste("Correlation: ", round(correlation, 2)), 
             hjust = 1.1, vjust = 2, size = 5, color = "black")
 
  ggsave(file.path(sub_dir, filename), plot = p, bg = 'white')
  print(p)
}
```

```{r}
# Create scatterplots for "2step" and "2step+"
create_scatterplot_with_correlation(stats_df, "2step", sub_dir = sub_dir, filename = "Scatterplot_2step.png")
create_scatterplot_with_correlation(stats_df, "2step+", sub_dir = sub_dir, filename = "Scatterplot_2step_plus.png")
```

```{r}
# Create scatterplots for "2step" and "2step+"
create_scatterplot_with_correlation(stats_df, "2step", log_scale = T, sub_dir = sub_dir, filename = "Scatterplot_2step_log.png")
create_scatterplot_with_correlation(stats_df, "2step+", log_scale = T, sub_dir = sub_dir, filename = "Scatterplot_2step_plus_log.png")
```



### Violin


```{r}
GeomSplitViolin <- ggproto("GeomSplitViolin", GeomViolin, 
                           draw_group = function(self, data, ..., draw_quantiles = NULL) {
  data <- transform(data, xminv = x - violinwidth * (x - xmin), xmaxv = x + violinwidth * (xmax - x))
  grp <- data[1, "group"]
  newdata <- plyr::arrange(transform(data, x = if (grp %% 2 == 1) xminv else xmaxv), if (grp %% 2 == 1) y else -y)
  newdata <- rbind(newdata[1, ], newdata, newdata[nrow(newdata), ], newdata[1, ])
  newdata[c(1, nrow(newdata) - 1, nrow(newdata)), "x"] <- round(newdata[1, "x"])

  if (length(draw_quantiles) > 0 & !scales::zero_range(range(data$y))) {
    stopifnot(all(draw_quantiles >= 0), all(draw_quantiles <=
      1))
    quantiles <- ggplot2:::create_quantile_segment_frame(data, draw_quantiles)
    aesthetics <- data[rep(1, nrow(quantiles)), setdiff(names(data), c("x", "y")), drop = FALSE]
    aesthetics$alpha <- rep(1, nrow(quantiles))
    both <- cbind(quantiles, aesthetics)
    quantile_grob <- GeomPath$draw_panel(both, ...)
    ggplot2:::ggname("geom_split_violin", grid::grobTree(GeomPolygon$draw_panel(newdata, ...), quantile_grob))
  }
  else {
    ggplot2:::ggname("geom_split_violin", GeomPolygon$draw_panel(newdata, ...))
  }
})

geom_split_violin <- function(mapping = NULL, data = NULL, stat = "ydensity", position = "identity", ..., 
                              draw_quantiles = NULL, trim = TRUE, scale = "area", na.rm = FALSE, 
                              show.legend = NA, inherit.aes = TRUE) {
  layer(data = data, mapping = mapping, stat = stat, geom = GeomSplitViolin, 
        position = position, show.legend = show.legend, inherit.aes = inherit.aes, 
        params = list(trim = trim, scale = scale, draw_quantiles = draw_quantiles, na.rm = na.rm, ...))
}
```


```{r}
# Subset the relevant columns
subset_df <- final_df[, c("M1-AI_MeanLFQ", "M1-AS_MeanLFQ", "M2-AI_MeanLFQ", "M2-AS_MeanLFQ")]

# Melt the data frame for easier plotting
melted_df <- melt(subset_df, variable.name = "Condition", value.name = "MeanLFQ")

# Create new columns for M1/M2 and AI/AS and log-transform MeanLFQ
melted_df <- melted_df %>%
  mutate(
    Method = ifelse(grepl("M1", Condition), "2Step+", "2Step"),
    Type = factor(ifelse(grepl("AI", Condition), "AI", "AS"), levels = c("AS", "AI")),
    LogMeanLFQ = log10(MeanLFQ)
  )


# Create the split violin plot with log-transformed MeanLFQ
p <- ggplot(melted_df, aes(x = Method, y = LogMeanLFQ, fill = Type)) +
  geom_split_violin() +
  labs(title = "Log-Transformed Mean LFQ Values by Method", x = "Method", y = "Log Mean LFQ") +
  theme_minimal() +
  scale_fill_manual(values = c("royalblue", "palegreen3"))

ggsave(file.path(sub_dir, "Violin_Methods.png"), plot = p, width = 10, height = 6, bg = 'white')

```

```{r}
# Subset the relevant columns
subset_df <- final_df[, c("M1-AI_MeanLFQ", "M1-AS_MeanLFQ", "M2-AI_MeanLFQ", "M2-AS_MeanLFQ")]

# Melt the data frame for easier plotting
melted_df <- melt(subset_df, variable.name = "Condition", value.name = "MeanLFQ")

# Create new columns for M1/M2 and AI/AS and log-transform MeanLFQ
melted_df <- melted_df %>%
  mutate(
    Method = ifelse(grepl("M1", Condition), "2Step+", "2Step"),
    Type = factor(ifelse(grepl("AI", Condition), "AI", "AS"), levels = c("AS", "AI")),
    LogMeanLFQ = log10(MeanLFQ)
  )


# Create the split violin plot with log-transformed MeanLFQ
p <- ggplot(melted_df, aes(x = Type, y = LogMeanLFQ, fill = Method)) +
  geom_split_violin() +
  labs(title = "Log-Transformed Mean LFQ Values by Buffer Type", x = "Buffer Type", y = "Log Mean LFQ") +
  theme_minimal() +
  scale_fill_manual(values = c("#E69F00", "#56B4E9"))

ggsave(file.path(sub_dir, "Violin_BufferTypes.png"), plot = p, width = 10, height = 6, bg = 'white')
```




## Inside 2step+

```{r}
sub_dir <- paste0(file.path(final_out_dir,"2stepplus"))
dir.create(sub_dir, recursive = TRUE, showWarnings = FALSE)
```

```{r}
# Filter dataset for "2step+" method
dataset_2step_plus <- dataset_merged[Method == "2step+" & !is.na(maxLfQ_intensities)]
dataset_2step_plus_repl <- dataset_filtered[, .(Unique_Repl_Biol_Count = uniqueN(Repl_Biol)), by = .(Method, Buffer_name, Buffer_type, ID)]
dataset_2step_plus_in_3_of_4 <- merge(
  dataset_2step_plus, 
  dataset_2step_plus_repl[Unique_Repl_Biol_Count >= 3][, .(Method, Buffer_name, ID)], 
  by = c("Method", "Buffer_name", "ID")
)

binary_presence <- dataset_2step_plus_in_3_of_4 %>%
  distinct(ID, Repl_Techn) %>%
  pivot_wider(names_from = Repl_Techn, values_from = Repl_Techn, 
              values_fill = list(Repl_Techn = 0), 
              values_fn = list(Repl_Techn = function(x) 1))  %>%
  tibble::column_to_rownames(var = "ID")

binary_presence <- binary_presence[, c(4,3,2,1)]

upset_plot <- ComplexUpset::upset(data=binary_presence, 
                    intersect=names(binary_presence), name="Technical Replicates", 
                     wrap=TRUE,
                    base_annotations=list(
                        'Intersection size'=intersection_size(
                            text=list(
                                size = 2.5
                            )
                        )
                    ),
                    set_sizes=(
                        upset_set_size()
                        + geom_text(aes(label=..count..), hjust=1.1, stat='count')
                        + annotate(geom='text', label='@', x='Count', y=850, color='white', size=3)
                        + expand_limits(y=7000)
                    ),
                    sort_sets=FALSE,
                    queries=list(
                        upset_query(
                            intersect = names(binary_presence),
                            color='darkred',
                            fill='darkred',
                            only_components=c('intersections_matrix', 'Intersection size')
                        ), 
                        upset_query(intersect = c("1"), color = "darkgreen", only_components=c('intersections_matrix')),
                        upset_query(intersect = c("2"), color = "darkgreen", only_components=c('intersections_matrix')),
                        upset_query(intersect = c("3"), color = "darkgreen", only_components=c('intersections_matrix')),
                        upset_query(intersect = c("4"), color = "darkgreen", only_components=c('intersections_matrix'))
                    ),
                    sort_intersections_by='degree') + ggtitle('Intersection of Quantified Proteins in 2Step+ for Technical Replicates')

ggsave(file.path(sub_dir, "technical_repl_intersection.png"), plot = upset_plot, width = 10, height = 6, bg = 'white')
```

### Intensities Variance

```{r}
ggplot(dataset_2step_plus_in_3_of_4, aes(x = as.factor(Repl_Techn), y = log10(maxLfQ_intensities), fill = Buffer_type)) +
  geom_boxplot() +
  facet_wrap(~Buffer_type) +
  labs(title = "Biological Variance in maxLfQ Intensities", x = "Technical Replicate", y = "Log10(maxLfQ Intensity)") +
  scale_fill_manual(values = c("AI" = "royalblue", "AS" = "palegreen3")) +
  theme_minimal()

ggplot(dataset_2step_plus_in_3_of_4, aes(x = as.factor(Repl_Biol), y = log10(maxLfQ_intensities), fill = Buffer_type)) +
  geom_boxplot() +
  facet_wrap(~Buffer_type) +
  labs(title = "Technical Variance in maxLfQ Intensities", x = "Biological Replicate", y = "Log10(maxLfQ Intensity)") +
  scale_fill_manual(values = c("AI" = "royalblue", "AS" = "palegreen3")) +
  theme_minimal()
```

```{r}
library(dplyr)

# Add a new column to distinguish between biological and technical variance
df <- dataset_2step_plus_in_3_of_4 %>%
  mutate(Variance_Type_Bio = "Biological Variance",
         Variance_Type_Tech = "Technical Variance")

# Prepare data for plotting biological variance
biological_variance <- df %>%
  select(Buffer_type, Buffer_name, Repl_Techn, maxLfQ_intensities, Variance_Type_Bio) %>%
  dplyr::rename(`Replicate` = `Repl_Techn`, `Variance_Type` = `Variance_Type_Bio`)

# Prepare data for plotting technical variance
technical_variance <- df %>%
  select(Buffer_type, Buffer_name, Repl_Techn, maxLfQ_intensities, Variance_Type_Tech) %>%
  dplyr::rename(`Replicate` = `Repl_Techn`, `Variance_Type` = `Variance_Type_Tech`)

# Combine the datasets
combined_variance <- bind_rows(biological_variance, technical_variance)

# Create the combined boxplot
p <- ggplot(combined_variance, aes(x = as.factor(Replicate), y = log10(maxLfQ_intensities), fill = Buffer_type)) +
  geom_boxplot() +
  facet_grid(Buffer_type ~ Variance_Type, scales = "free_x") +
  labs(title = "Biological and Technical Variance in maxLfQ Intensities",
       x = "Replicate", y = "Log10(maxLfQ Intensity)") +
  scale_fill_manual(values = c("AI" = "royalblue", "AS" = "palegreen3")) +
  theme_minimal()

# Print and save the plot
print(p)

ggsave(file.path(sub_dir, "Combined_Variance_maxLfQ.png"), plot = p, width = 12, height = 8, bg = 'white')
```

### Intensities in General

```{r}
# Create a new dataset with descriptive names for technical replicates
dataset_2step_plus_in_3_of_4_labeled <- dataset_2step_plus_in_3_of_4 %>%
  mutate(Repl_Techn_Label = paste("Technical Replicate", Repl_Techn))

# Create the box plot with 4 columns in the facet_wrap
p <- ggplot(dataset_2step_plus_in_3_of_4_labeled, aes(x = as.factor(Repl_Biol), y = log10(maxLfQ_intensities), fill = Buffer_type)) +
  geom_boxplot() +
  facet_wrap(Buffer_type ~ Repl_Techn_Label, ncol = 4) +
  labs(title = "maxLfQ Intensities by Buffer Type and Replicate Biological", x = "Biological Replicate", y = "Log10(maxLfQ Intensity)") +
  scale_fill_manual(values = c("AI" = "royalblue", "AS" = "palegreen3")) +
  theme_minimal()

# Print the plot
print(p)
```

```{r}
# Create a new dataset with descriptive names for technical replicates
dataset_2step_plus_in_3_of_4_labeled <- dataset_2step_plus_in_3_of_4 %>%
  mutate(Repl_Biol_Label = paste("Biological Replicate", Repl_Biol))

# Create the box plot with 4 columns in the facet_wrap
p <- ggplot(dataset_2step_plus_in_3_of_4_labeled, aes(x = as.factor(Repl_Techn), y = log10(maxLfQ_intensities), fill = Buffer_type)) +
  geom_boxplot() +
  facet_wrap(Buffer_type ~ Repl_Biol_Label, ncol = 4) +
  labs(title = "maxLfQ Intensities by Buffer Type and Technical Biological", x = "Technical Replicate", y = "Log10(maxLfQ Intensity)") +
  scale_fill_manual(values = c("AI" = "royalblue", "AS" = "palegreen3")) +
  theme_minimal()

# Print the plot
print(p)
```



### Statistics

```{r}
stats_df_bio <- dataset_2step_plus_in_3_of_4 %>%
  group_by(ID, Protein.Group, Genes, First.Protein.Description, Method, Buffer_name, Repl_Techn) %>%
  summarize(
    MedianLFQ = median(maxLfQ_intensities, na.rm = TRUE),
    MeanLFQ = mean(maxLfQ_intensities, na.rm = TRUE),
    SDLFQ = sd(maxLfQ_intensities, na.rm = TRUE),
    CVLFQ = (sd(maxLfQ_intensities, na.rm = TRUE) / mean(maxLfQ_intensities, na.rm = TRUE)) * 100,
    .groups = 'drop') %>%
  dplyr::rename(`Replicate` = `Repl_Techn`) %>%
  mutate(`Variance_Type` = "Biological Variance")

stats_df_tech <- dataset_2step_plus_in_3_of_4 %>%
  group_by(ID, Protein.Group, Genes, First.Protein.Description, Method, Buffer_name, Repl_Biol) %>%
  summarize(
    MedianLFQ = median(maxLfQ_intensities, na.rm = TRUE),
    MeanLFQ = mean(maxLfQ_intensities, na.rm = TRUE),
    SDLFQ = sd(maxLfQ_intensities, na.rm = TRUE),
    CVLFQ = (sd(maxLfQ_intensities, na.rm = TRUE) / mean(maxLfQ_intensities, na.rm = TRUE)) * 100,
    .groups = 'drop') %>%
  dplyr::rename(`Replicate` = `Repl_Biol`) %>%
  mutate(`Variance_Type` = "Technical Variance")

combined_variance_stats <- bind_rows(stats_df_tech, stats_df_bio)
```

```{r}
# Define a function to create and save plots
create_and_save_plot <- function(df, y_var, log_transform = FALSE, sub_dir, filename) {
  p <- ggplot(df, aes(x = as.factor(Replicate), y = if (log_transform) log10(!!sym(y_var)) else !!sym(y_var), fill = Buffer_name)) +
    geom_boxplot() +
    facet_grid( Buffer_name ~ Variance_Type, scales = "free_x") +
    labs(title = paste("Biological and Technical Variance in", y_var),
         x = "Replicate", y = if (log_transform) paste("Log10(", y_var, ")", sep = "") else y_var) +
    scale_fill_manual(values = c("AI" = "royalblue", "AS" = "palegreen3")) +
    theme_minimal()
  
  # Print the plot
  print(p)
  
  # Save the plot
  ggsave(file.path(sub_dir, filename), plot = p, width = 12, height = 8, bg = 'white')
}


# Plot for MeanLFQ with log10 transformation
create_and_save_plot(combined_variance_stats, "MeanLFQ", log_transform = TRUE, sub_dir, "Variance_MeanLFQ_Boxplot.png")

# Plot for SDLFQ with log10 transformation
create_and_save_plot(combined_variance_stats, "SDLFQ", log_transform = TRUE, sub_dir, "Variance_SDLFQ_Boxplot.png")

# Plot for CVLFQ without log10 transformation
create_and_save_plot(combined_variance_stats, "CVLFQ", log_transform = FALSE, sub_dir, "Variance_CVLFQ_Boxplot.png")

```


```{r}
# Load necessary libraries
library(ggplot2)
library(dplyr)
library(patchwork)  # For combining plots

# Create scatter plots for each replicate
plots <- list()
for (replicate in 1:4) {
  filtered_stats_df <- stats_df_tech %>%
    filter(Replicate == replicate) %>%
    select(-Replicate, -Variance_Type)
  
  plot <- create_scatterplot_with_correlation(filtered_stats_df, "2step+", log_scale = TRUE, sub_dir = sub_dir, filename = "test.png") +
    labs(title = paste("Technical Replicate", replicate))
  plots[[replicate]] <- plot
}

# Combine the plots into a single plot
combined_plot <- wrap_plots(plots, ncol = 2)

# Print the combined plot
print(combined_plot)



```


```{r}
# Create the split violin plot for each technical replicate
p <- ggplot(stats_df_tech, aes(x = as.factor(Replicate), y = log10(MeanLFQ), fill = Buffer_name)) +
  geom_split_violin(trim = FALSE) +
  labs(title = "Log-Transformed Mean LFQ Values by Technical Replicate", x = "Technical Replicate", y = "Log Mean LFQ") +
  theme_minimal() +
  scale_fill_manual(values = c("AI" = "royalblue", "AS" = "palegreen3"))

print(p)
```


```{r}
# Load necessary libraries
library(ggplot2)
library(dplyr)
library(tidyr)
library(patchwork)  # For combining plots

# Function to create scatter plot with density
create_density_scatterplot <- function(df, x_var, y_var, buffer_name) {
  # Filter the dataset for the specified buffer name
  filtered_df <- df %>%
    filter(Buffer_name == buffer_name)
  
  # Calculate the correlation
  correlation <- cor(filtered_df[[x_var]], filtered_df[[y_var]], use = "complete.obs")
  
  # Create the scatter plot with density
  p <- ggplot(filtered_df, aes_string(x = x_var, y = y_var, color = "Buffer_name")) +
    geom_point(alpha = 0.6) +
    geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "gray") +
    labs(x = x_var,
         y = y_var) +
    theme_minimal() +
    coord_equal() +
    scale_color_manual(values = c("AI" = "royalblue", "AS" = "palegreen3")) +
    annotate("text", x = Inf, y = Inf, label = paste("Cor: ", round(correlation, 2)), 
             hjust = 1.1, vjust = 2, size = 5, color = "black") +
    guides(fill = "none", color = "none")
  
  return(p)
}

# Prepare the dataset for plotting
df <- stats_df_tech %>%
  filter(Method == "2step+") %>%
  select(ID, Buffer_name, Replicate, MeanLFQ) %>%
  spread(key = Replicate, value = MeanLFQ, sep = "_") %>%
  filter(!is.na(Replicate_1) & !is.na(Replicate_2) & !is.na(Replicate_3) & !is.na(Replicate_4))

# Create a list to hold all the plots
all_plots <- list()

# Loop through Buffer_name, Replicate combinations to create the plots
for (buffer_name in unique(df$Buffer_name)) {
  for (i in 1:4) {
    for (j in 1:4) {
      if (i != j) {
        x_var <- paste0("Replicate_", i)
        y_var <- paste0("Replicate_", j)
        plot <- create_density_scatterplot(df, x_var, y_var, buffer_name)
        all_plots[[length(all_plots) + 1]] <- plot
      }
    }
  }
}

# Combine the plots into a single plot
combined_plot <- wrap_plots(all_plots, ncol = 4)

# Print the combined plot
print(combined_plot)

```

